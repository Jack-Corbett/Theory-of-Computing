# Computational Complexity

## Terminology

The aims of measuring complexity are:

- Measuring how the time/space required by an algorithm/problem increases as the input gets larger,
- Classifying problems according to their complexity

**Problem** is a computational problem with a set of possible inputs and prescribed corresponding outputs

**Algorithm** is a procedure for solving a problem

**Problem Instance** is a particular possible input to a given problem

## Complexity

The complexity of an algorithm is how much the algorithm costs, as a function of the problem instance size.

This requires: 

- A measure of problem instance size
  - number of blocks,
  - length of an array,
  - number of vertices in a graph
- A measure of algorithm cost on a given instance I
  - could be the **time** taken by the algorithm on the problem instance I,
    - number of moves in Towers of Hanoi,
    - number of comparisons in sorting,
    - number of basic operations in a conventional program
- could also be the **memory** used in running the algorithm on I

![Screenshot 2018-12-05 at 14.37.16](/Users/jackcorbett/Documents/University/Theory of Computing/Part 2/Images/Complexity.png)

### Big O

The **worst case** complexity - the idea is that it gives an upper bound for the growth of an algorithm

**Algorithm**: $f(n)$ is $O(g(n))$ for some equation $g(n)$, that means that the algorithm’s complexity scales, at worst, with $g(n)$, but it could do better in certain cases.

**Problem**: $f(n)$ is $O(g(n))$ for some equation $g(n)$, that means our best algorithm can solve this problem with complexity $g(n)$. There might exist an algorithm that does better, but we haven’t discovered it yet.

### Big $\theta$ 

The **average case** complexity. 

**Algorithm**: $f(n)$ is $\theta(g(n))$ for some equation $g(n)$, that means that the algorithm’s complexity scales with $g(n)$ and can only scale by $g(n)$, it can do no better than that.

**Problem**: $f(n)$ is $\theta(g(n))$ for some equation $g(n)$, that means that the only algorithms that can solve the problem $f(n)$ must have complexity $g(n)$

## Machine Speed

If we can solve a size n problem instance in 1 hour if we double the machine speed, we can use the complexity to work out how much of an improvement we will get.

![Screenshot 2018-11-29 at 09.45.09](/Users/jackcorbett/Documents/University/Theory of Computing/Part 2/Images/Machine Speed.png)

# Feasability

An algorithm is said to be **feasable** if it has an algorithm with time complexity $\leq$ some *polynomial* f(n)

A problem which can be solved in finite time, but has not polynomial time algorithm is said to be **infeasable**

> This means infeasable problems are still computable, just not efficiently...

## Decision Problems

A computational problem is called a **decision problem** if the output for any problem instance is either “yes” or “no”.

We classify problem instances into positive/“yes” instances and negative/“no” instances.
